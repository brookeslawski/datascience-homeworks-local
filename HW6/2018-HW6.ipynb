{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science – Homework 6\n",
    "*COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/*\n",
    "\n",
    "Due: Friday, February 23, 11:59pm.\n",
    "\n",
    "In Part 1 of this homework you will scrape github repositories and organize the information in a Pandas dataframe. In Part 2, you will use linear regression to gain meaningful insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Data\n",
    "First Name:\n",
    "<br>\n",
    "Last Name:\n",
    "<br>\n",
    "E-mail:\n",
    "<br>\n",
    "UID:\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports and setup \n",
    "from bs4 import BeautifulSoup\n",
    "# you can use either of these libraries to get html from a website\n",
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scrape Github Repository List and Repository Information using BeautifulSoup\n",
    "In this part you will explore over 2 million Github repositories. You are going to scrape [this repository list](https://github.com/search?o=desc&q=stars%3A%3E1&s=stars&type=Repositories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Check whether you are permitted to scrape the data\n",
    "Before you start to scrape any website you should go through the terms and services or similar pages of the website. Almost all websites post conditions to use their data. Check the terms of [https://github.com/](https://github.com/) to see whether the site permits you to scrape their data or not. Are you sure you are allowed to scrape?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Interpretation:**\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 Download the website\n",
    "\n",
    "Download the **first ten** pages of the list of highly starred repositories here: \n",
    "\n",
    "https://github.com/search?o=desc&q=stars%3A%3E1&s=stars&type=Repositories\n",
    "\n",
    "To avoid sending too many requests to the server, make sure that your querying code is in a sperate cell from anything else, so that you don't have to re-run it needlessly. \n",
    "\n",
    "**Warning:** while we haven't experienced any problems, exepct that github will temporarily block access if you scrape their website relentlessly. Make sure to be responsible. Also, don't do this last minute – if you're blocked for e.g., 24 hours that could impact your timeline.\n",
    "\n",
    "Now read the html text in python and create a soup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\U0001f4da' in position 32923: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-68b1e520ece9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# save the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'git_repositories.html'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnew_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mnew_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# here it's already a local operation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\U0001f4da' in position 32923: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "## Your code goes here\n",
    "\n",
    "# download the fist ten pages\n",
    "url = \"https://github.com/search?o=desc&p=1&q=stars%3A%3E1&s=stars&type=Repositories\"\n",
    "\n",
    "# with urllib.request.urlopen(url) as response:\n",
    "#     html = response.read()\n",
    "#     html = html.decode('utf-8')\n",
    "\n",
    "#A simple solution is to just use ‘response.text’ to get html returned by requests.get(url) directly.\n",
    "    \n",
    "html = requests.get(url)\n",
    "html = html.text\n",
    "\n",
    "# save the file\n",
    "with open('git_repositories.html', 'w') as new_file:\n",
    "    new_file.write(html)\n",
    "\n",
    "# here it's already a local operation\n",
    "git_soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Extract Data\n",
    "\n",
    "Extract the foolowing data for each repository, and create a Pandas Dataframe with a row for each repository and a column for each of these datums. \n",
    "\n",
    "1. Name of the repository\n",
    "+ URL of the repository \n",
    "+ Number of Contributors \n",
    "+ Programming Language Used \n",
    "+ Number of stars \n",
    "+ Number of issues\n",
    "+ Number of files \n",
    "+ Length of readme file.\n",
    "\n",
    "Note that you will frist have to extract links from the soup that you just scraped earlier, and then download the repository pages to retreive most of the data. \n",
    "\n",
    "Refer to lecture 12 for details on how to do this. Make sure to use the web inspector to identify the relevant structures. \n",
    "\n",
    "Save the dataframe you created to a new file `project_info.csv` and include this in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert list into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save dataframe to file project_info.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use linear regression to analyze the Github repository data\n",
    "\n",
    "In this part, you will analyze the data collectd in Part 1 using regression tools. The goal is to identify properties that make a repository popular. \n",
    "\n",
    "First, load the project_info.csv file in again. **We need you to do this so that we can run your code below withouth having to run your scraping code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Name</th>\n",
       "      <th>Language</th>\n",
       "      <th>Stars</th>\n",
       "      <th>URL</th>\n",
       "      <th>Forks</th>\n",
       "      <th>Contributors</th>\n",
       "      <th>Issues</th>\n",
       "      <th>ReadmeLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freeCodeCamp/freeCodeCamp</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>292k</td>\n",
       "      <td>https://github.com/freeCodeCamp/freeCodeCamp</td>\n",
       "      <td>8,409</td>\n",
       "      <td>731</td>\n",
       "      <td>165</td>\n",
       "      <td>2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twbs/bootstrap</td>\n",
       "      <td>CSS</td>\n",
       "      <td>122k</td>\n",
       "      <td>https://github.com/twbs/bootstrap</td>\n",
       "      <td>7,279</td>\n",
       "      <td>982</td>\n",
       "      <td>312</td>\n",
       "      <td>5032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EbookFoundation/free-programming-books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101k</td>\n",
       "      <td>https://github.com/EbookFoundation/free-progra...</td>\n",
       "      <td>7,387</td>\n",
       "      <td>978</td>\n",
       "      <td>16</td>\n",
       "      <td>1586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensorflow/tensorflow</td>\n",
       "      <td>C++</td>\n",
       "      <td>89.7k</td>\n",
       "      <td>https://github.com/tensorflow/tensorflow</td>\n",
       "      <td>7,449</td>\n",
       "      <td>1,337</td>\n",
       "      <td>1,194</td>\n",
       "      <td>3028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>88.5k</td>\n",
       "      <td>https://github.com/facebook/react</td>\n",
       "      <td>5,521</td>\n",
       "      <td>1,167</td>\n",
       "      <td>320</td>\n",
       "      <td>3311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Repository Name    Language  Stars  \\\n",
       "0               freeCodeCamp/freeCodeCamp  JavaScript   292k   \n",
       "1                          twbs/bootstrap         CSS   122k   \n",
       "2  EbookFoundation/free-programming-books         NaN   101k   \n",
       "3                   tensorflow/tensorflow         C++  89.7k   \n",
       "4                          facebook/react  JavaScript  88.5k   \n",
       "\n",
       "                                                 URL  Forks Contributors  \\\n",
       "0       https://github.com/freeCodeCamp/freeCodeCamp  8,409          731   \n",
       "1                  https://github.com/twbs/bootstrap  7,279          982   \n",
       "2  https://github.com/EbookFoundation/free-progra...  7,387          978   \n",
       "3           https://github.com/tensorflow/tensorflow  7,449        1,337   \n",
       "4                  https://github.com/facebook/react  5,521        1,167   \n",
       "\n",
       "  Issues  ReadmeLength  \n",
       "0    165          2798  \n",
       "1    312          5032  \n",
       "2     16          1586  \n",
       "3  1,194          3028  \n",
       "4    320          3311  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this loads the data from the project_info.csv file \n",
    "project_info = pd.read_csv('project_info.csv')\n",
    "project_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.1. Reformat the data into useful datatypes\n",
    "\n",
    "1. Print the data types for the columns of your dataframe\n",
    "+ Reformat the colums Issues, Forks, Stars, and Contributers to be integer data\n",
    "+ There is one repository flagged as having infinite contributers (the Linux kernel). We'll assume that it in fact has 15000 contributors (about twice as much as the next project). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 Describe the data\n",
    "\n",
    "+ Get an overview of the data using the describe function.\n",
    "+ Compute the correlation matrix, visualize it with a heat map.\n",
    "+ Visualize the correlations by making a scatterplot matrix.\n",
    "+ Interprete what you see.\n",
    "\n",
    "You can re-use code from your previous homework here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Interpretation:** TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Linear regression\n",
    "\n",
    "1. First use linear regression to try to predict the number of Stars based on Forks, Contributors, Issues, and Readme Length. Explain why this is not a very good model by discussing the R-squared , F-statistic p-value, and coefficient  p-values. \n",
    "+ Develop another model which is better. Explain why it is better and interpret your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your interpretation:** TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
